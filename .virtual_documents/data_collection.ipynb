pip install requests


import requests


URL="https://stephen-king-api.onrender.com/api/books"

res=requests.get(URL)
res


json_data=res.json()


import pandas as pd

df=pd.json_normalize(json_data["data"])


df=df[["id","Year","Title","ISBN"]]


df


URL="https://api.openbrewerydb.org/v1/breweries"

res=requests.get(URL)
res


json_data=res.json()
json_data
df=pd.json_normalize(json_data)
df=df[["name","city"]]



URL="https://www.scrapethissite.com/pages/simple/"

res=requests.get(URL);



if res.status_code==200:
    print(res.text)


with open("scraped_data/data1.html", "w", encoding="utf-8") as f:
    f.write(res.text)


pip install beautifulsoup4


from bs4 import BeautifulSoup

with open("scraped_data/data1.html","r") as f:
    html_data=f.read()

soup=BeautifulSoup(html_data, "lxml")
print(soup.find("h1"))
all_h3=soup.find_all("h3")

all_countries=[]


for h3 in all_h3:
    name=h3.get_text(strip=True)
    # print(h3.find_parent("div")["class"])
    population=h3.find_next("div").select("span.country-population")[0].get_text(strip=True)
    print(h3.find_next("div").select_one("span.country-population").get_text(strip=True))
    all_countries.append([name, population])




import pandas as pd

df=pd.DataFrame(all_countries, columns=["name", "population"])


df.to_csv("cleaned_data/data.csv", index=False)






